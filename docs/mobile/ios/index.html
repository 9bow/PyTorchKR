<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
  <title>
    
      iOS | PyTorch
    
  </title>
  <meta property="og:title" content="PyTorch Korea User Group" />
<meta
  name="description"
  property="og:description"
  content="(Unofficial) Korean user community for PyTorch which is an open source machine learning framework that accelerates the path from research prototyping to production deployment."
/>
<meta property="og:url" content="https://www.pytorch.kr" />
<meta property="og:type" content="website" />
<meta
  property="og:image"
  content="http://localhost:4000/assets/images/pytorch-kr-logo.png"
/>
<meta name="robots" content="index, follow" />

  <link rel="stylesheet" href="/assets/main.css">
  <script src="/assets/vendor/jquery.min.js"></script>
  <script src="/assets/vendor/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap.min.js"></script>
  <script src="/assets/vendor/anchor.min.js"></script>
</head>

  <body class="mobile">
    <div class="container-fluid header-holder mobile-header">
  <div class="container">
    

<div class="header-container">
  <a class="header-logo" href="http://localhost:4000" aria-label="PyTorch"></a>

  <div class="main-menu">
  <ul>
    <li class="main-menu-item ">
      <a href="/get-started">시작하기</a>
    </li>

    <li class="main-menu-item">
      <a href="https://tutorials.pytorch.kr/">튜토리얼</a>
    </li>

    <li class="main-menu-item ">
      <a href="/hub">허브</a>
    </li>

    <li class="main-menu-item">
      <a href="https://discuss.pytorch.kr">커뮤니티</a>
    </li>

  </ul>
</div>

<script src="/assets/main-menu-dropdown.js"></script>


  <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
</div>

  </div>
</div>


    <div class="main-background mobile-background"></div>

    

    <div class="jumbotron jumbotron-fluid on-dark-background">
      <div class="container">
        <h1>PyTorch Mobile</h1>

        <p class="lead">End-to-end workflow from Training to Deployment for iOS and Android mobile devices</p>
      </div>
    </div>

    <div class="main-content-wrapper">
      <div class="main-content">
        <div class="container-fluid nav-menu-wrapper">
          <div class="container">
            <nav class="navbar navbar-expand-lg navbar-light main-content-menu">
              <ul class="navbar-nav">
                
                  <li class="nav-item nav-select">
                    <a class="nav-link" data-id="home" href="/mobile/home/">Home</a>
                  </li>
                
                  <li class="nav-item nav-select">
                    <a class="nav-link" data-id="ios" href="/mobile/ios/">iOS</a>
                  </li>
                
                  <li class="nav-item nav-select">
                    <a class="nav-link" data-id="android" href="/mobile/android/">Android</a>
                  </li>
                
              </ul>
            </nav>
          </div>
        </div>

        <div class="container">
          <div class="row">
            <div class="col-md-3">
              <div class="sticky-top mobile-page-sidebar">
  <p id="shortcuts-menu">Shortcuts</p>
  <ul id="mobile-page-sidebar-list"></ul>
</div>


            </div>
            <div class="col-md-8 offset-md-1">
              <div class="article-wrapper" data-id="">
                <article class="pytorch-article">
                  <h1 id="ios">iOS</h1>

<p>To get started with PyTorch on iOS, we recommend exploring the following <a href="https://github.com/pytorch/ios-demo-app/tree/master/HelloWorld">HelloWorld</a>.</p>

<h2 id="quickstart-with-a-hello-world-example">Quickstart with a Hello World Example</h2>

<p>HelloWorld is a simple image classification application that demonstrates how to use PyTorch C++ libraries on iOS. The code is written in Swift and uses Objective-C as a bridge.</p>

<h3 id="model-preparation">Model Preparation</h3>

<p>Let’s start with model preparation. If you are familiar with PyTorch, you probably should already know how to train and save your model. In case you don’t, we are going to use a pre-trained image classification model - <a href="https://pytorch.org/hub/pytorch_vision_mobilenet_v2/">MobileNet v2</a>, which is already packaged in <a href="https://pytorch.org/docs/stable/torchvision/index.html">TorchVision</a>. To install it, run the command below.</p>

<blockquote>
  <p>We highly recommend following the <a href="https://github.com/pytorch/pytorch">Pytorch Github page</a> to set up the Python development environment on your local machine.</p>
</blockquote>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>torchvision
</code></pre></div></div>

<p>Once we have TorchVision installed successfully, let’s navigate to the HelloWorld folder and run <code class="language-plaintext highlighter-rouge">trace_model.py</code>. The script contains the code of tracing and saving a <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html">torchscript model</a> that can be run on mobile devices.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python trace_model.py
</code></pre></div></div>

<p>If everything works well, we should have our model - <code class="language-plaintext highlighter-rouge">model.pt</code> generated in the <code class="language-plaintext highlighter-rouge">HelloWorld</code> folder. Now copy the model file to our application folder <code class="language-plaintext highlighter-rouge">HelloWorld/model</code>.</p>

<blockquote>
  <p>To find out more details about TorchScript, please visit <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">tutorials on pytorch.org</a></p>
</blockquote>

<h3 id="install-libtorch-via-cocoapods">Install LibTorch via Cocoapods</h3>

<p>The PyTorch C++ library is available in <a href="https://cocoapods.org/">Cocoapods</a>, to integrate it to our project, simply run</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pod</span> <span class="n">install</span>
</code></pre></div></div>

<p>Now it’s time to open the <code class="language-plaintext highlighter-rouge">HelloWorld.xcworkspace</code> in XCode, select an iOS simulator and launch it (cmd + R). If everything works well, we should see a wolf picture on the simulator screen along with the prediction result.</p>

<p><img src="https://github.com/pytorch/ios-demo-app/blob/master/HelloWorld/screenshot.png?raw=true" width="50%" /></p>

<h3 id="code-walkthrough">Code Walkthrough</h3>

<p>In this part, we are going to walk through the code step by step.</p>

<h4 id="image-loading">Image Loading</h4>

<p>Let’s begin with image loading.</p>

<div class="language-swift highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="nv">image</span> <span class="o">=</span> <span class="kt">UIImage</span><span class="p">(</span><span class="nv">named</span><span class="p">:</span> <span class="s">"image.jpg"</span><span class="p">)</span><span class="o">!</span>
<span class="n">imageView</span><span class="o">.</span><span class="n">image</span> <span class="o">=</span> <span class="n">image</span>
<span class="k">let</span> <span class="nv">resizedImage</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="nf">resized</span><span class="p">(</span><span class="nv">to</span><span class="p">:</span> <span class="kt">CGSize</span><span class="p">(</span><span class="nv">width</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span> <span class="nv">height</span><span class="p">:</span> <span class="mi">224</span><span class="p">))</span>
<span class="k">guard</span> <span class="k">var</span> <span class="nv">pixelBuffer</span> <span class="o">=</span> <span class="n">resizedImage</span><span class="o">.</span><span class="nf">normalized</span><span class="p">()</span> <span class="k">else</span> <span class="p">{</span>
    <span class="k">return</span>
<span class="p">}</span>
</code></pre></div></div>

<p>We first load the image from our bundle and resize it to 224x224. Then we call this <code class="language-plaintext highlighter-rouge">normalized()</code> category method to normalized the pixel buffer. Let’s take a closer look at the code below.</p>

<div class="language-swift highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">var</span> <span class="nv">normalizedBuffer</span><span class="p">:</span> <span class="p">[</span><span class="kt">Float32</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="kt">Float32</span><span class="p">](</span><span class="nv">repeating</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="nv">count</span><span class="p">:</span> <span class="n">w</span> <span class="o">*</span> <span class="n">h</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span>
<span class="c1">// normalize the pixel buffer</span>
<span class="c1">// see https://pytorch.org/hub/pytorch_vision_resnet/ for more detail</span>
<span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">0</span> <span class="o">..&lt;</span> <span class="n">w</span> <span class="o">*</span> <span class="n">h</span> <span class="p">{</span>
    <span class="n">normalizedBuffer</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>             <span class="o">=</span> <span class="p">(</span><span class="kt">Float32</span><span class="p">(</span><span class="n">rawBytes</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="mf">255.0</span> <span class="o">-</span> <span class="mf">0.485</span><span class="p">)</span> <span class="o">/</span> <span class="mf">0.229</span> <span class="c1">// R</span>
    <span class="n">normalizedBuffer</span><span class="p">[</span><span class="n">w</span> <span class="o">*</span> <span class="n">h</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span>     <span class="o">=</span> <span class="p">(</span><span class="kt">Float32</span><span class="p">(</span><span class="n">rawBytes</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mf">255.0</span> <span class="o">-</span> <span class="mf">0.456</span><span class="p">)</span> <span class="o">/</span> <span class="mf">0.224</span> <span class="c1">// G</span>
    <span class="n">normalizedBuffer</span><span class="p">[</span><span class="n">w</span> <span class="o">*</span> <span class="n">h</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="kt">Float32</span><span class="p">(</span><span class="n">rawBytes</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="mi">2</span><span class="p">])</span> <span class="o">/</span> <span class="mf">255.0</span> <span class="o">-</span> <span class="mf">0.406</span><span class="p">)</span> <span class="o">/</span> <span class="mf">0.225</span> <span class="c1">// B</span>
<span class="p">}</span>
</code></pre></div></div>

<p>The code might look weird at first glance, but it’ll make sense once we understand our model. The input data is a 3-channel RGB image of shape (3 x H x W), where H and W are expected to be at least 224. The image has to be loaded in to a range of <code class="language-plaintext highlighter-rouge">[0, 1]</code> and then normalized using <code class="language-plaintext highlighter-rouge">mean = [0.485, 0.456, 0.406]</code> and <code class="language-plaintext highlighter-rouge">std = [0.229, 0.224, 0.225]</code>.</p>

<h4 id="torchscript-module">TorchScript Module</h4>

<p>Now that we have preprocessed our input data and we have a pre-trained TorchScript model, the next step is to use them to run predication. To do that, we’ll first load our model into the application.</p>

<div class="language-swift highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">private</span> <span class="kd">lazy</span> <span class="k">var</span> <span class="nv">module</span><span class="p">:</span> <span class="kt">TorchModule</span> <span class="o">=</span> <span class="p">{</span>
    <span class="k">if</span> <span class="k">let</span> <span class="nv">filePath</span> <span class="o">=</span> <span class="kt">Bundle</span><span class="o">.</span><span class="n">main</span><span class="o">.</span><span class="nf">path</span><span class="p">(</span><span class="nv">forResource</span><span class="p">:</span> <span class="s">"model"</span><span class="p">,</span> <span class="nv">ofType</span><span class="p">:</span> <span class="s">"pt"</span><span class="p">),</span>
        <span class="k">let</span> <span class="nv">module</span> <span class="o">=</span> <span class="kt">TorchModule</span><span class="p">(</span><span class="nv">fileAtPath</span><span class="p">:</span> <span class="n">filePath</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">module</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="nf">fatalError</span><span class="p">(</span><span class="s">"Can't find the model file!"</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}()</span>
</code></pre></div></div>
<p>Note that the <code class="language-plaintext highlighter-rouge">TorchModule</code> Class is an Objective-C wrapper of <code class="language-plaintext highlighter-rouge">torch::jit::script::Module</code>.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">script</span><span class="o">::</span><span class="n">Module</span> <span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="n">filePath</span><span class="p">.</span><span class="n">UTF8String</span><span class="p">);</span>
</code></pre></div></div>
<p>Since Swift can not talk to C++ directly, we have to either use an Objective-C class as a bridge, or create a C wrapper for the C++ library. For demo purpose, we’re going to wrap everything in this Objective-C class.</p>

<h4 id="run-inference">Run Inference</h4>

<p>Now it’s time to run inference and get the results.</p>

<div class="language-swift highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">guard</span> <span class="k">let</span> <span class="nv">outputs</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="nf">predict</span><span class="p">(</span><span class="nv">image</span><span class="p">:</span> <span class="kt">UnsafeMutableRawPointer</span><span class="p">(</span><span class="o">&amp;</span><span class="n">pixelBuffer</span><span class="p">))</span> <span class="k">else</span> <span class="p">{</span>
    <span class="k">return</span>
<span class="p">}</span>
</code></pre></div></div>
<p>Again, the <code class="language-plaintext highlighter-rouge">predict</code> method is just an Objective-C wrapper. Under the hood, it calls the C++ <code class="language-plaintext highlighter-rouge">forward</code> function. Let’s take a look at how it’s implemented.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">::</span><span class="n">from_blob</span><span class="p">(</span><span class="n">imageBuffer</span><span class="p">,</span> <span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">},</span> <span class="n">at</span><span class="o">::</span><span class="n">kFloat</span><span class="p">);</span>
<span class="n">torch</span><span class="o">::</span><span class="n">autograd</span><span class="o">::</span><span class="n">AutoGradMode</span> <span class="nf">guard</span><span class="p">(</span><span class="nb">false</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">outputTensor</span> <span class="o">=</span> <span class="n">_impl</span><span class="p">.</span><span class="n">forward</span><span class="p">({</span><span class="n">tensor</span><span class="p">}).</span><span class="n">toTensor</span><span class="p">();</span>
<span class="kt">float</span><span class="o">*</span> <span class="n">floatBuffer</span> <span class="o">=</span> <span class="n">outputTensor</span><span class="p">.</span><span class="n">data_ptr</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">();</span>
</code></pre></div></div>
<p>The C++ function <code class="language-plaintext highlighter-rouge">torch::from_blob</code> will create an input tensor from the pixel buffer. Note that the shape of the tensor is <code class="language-plaintext highlighter-rouge">{1,3,224,224}</code> which represents <code class="language-plaintext highlighter-rouge">NxCxWxH</code> as we discussed in the above section.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="o">::</span><span class="n">autograd</span><span class="o">::</span><span class="n">AutoGradMode</span> <span class="nf">guard</span><span class="p">(</span><span class="nb">false</span><span class="p">);</span>
<span class="n">at</span><span class="o">::</span><span class="n">AutoNonVariableTypeMode</span> <span class="nf">non_var_type_mode</span><span class="p">(</span><span class="nb">true</span><span class="p">);</span>
</code></pre></div></div>
<p>The above two lines tells the PyTorch engine to do inference only. This is because by default, PyTorch has built-in support for doing auto-differentiation, which is also known as <a href="https://pytorch.org/docs/stable/notes/autograd.html">autograd</a>. Since we don’t do training on mobile, we can just disable the autograd mode.</p>

<p>Finally, we can call this <code class="language-plaintext highlighter-rouge">forward</code> function to get the output tensor and convert it to a <code class="language-plaintext highlighter-rouge">float</code> buffer.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">auto</span> <span class="n">outputTensor</span> <span class="o">=</span> <span class="n">_impl</span><span class="p">.</span><span class="n">forward</span><span class="p">({</span><span class="n">tensor</span><span class="p">}).</span><span class="n">toTensor</span><span class="p">();</span>
<span class="kt">float</span><span class="o">*</span> <span class="n">floatBuffer</span> <span class="o">=</span> <span class="n">outputTensor</span><span class="p">.</span><span class="n">data_ptr</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">();</span>
</code></pre></div></div>

<h3 id="collect-results">Collect Results</h3>

<p>The output tensor is a one-dimensional float array of shape 1x1000, where each value represents the confidence that a label is predicted from the image. The code below sorts the array and retrieves the top three results.</p>

<div class="language-swift highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="nv">zippedResults</span> <span class="o">=</span> <span class="nf">zip</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="k">let</span> <span class="nv">sortedResults</span> <span class="o">=</span> <span class="n">zippedResults</span><span class="o">.</span><span class="n">sorted</span> <span class="p">{</span> <span class="nv">$0</span><span class="o">.</span><span class="mi">1</span><span class="o">.</span><span class="n">floatValue</span> <span class="o">&gt;</span> <span class="nv">$1</span><span class="o">.</span><span class="mi">1</span><span class="o">.</span><span class="n">floatValue</span> <span class="p">}</span><span class="o">.</span><span class="nf">prefix</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="pytorch-demo-app">PyTorch Demo App</h2>

<p>For more complex use cases, we recommend to check out the <a href="https://github.com/pytorch/ios-demo-app">PyTorch demo application</a>. The demo app contains two showcases. A camera app that runs a quantized model to predict the images coming from device’s rear-facing camera in real time. And a text-based app that uses a text classification model to predict the topic from the input string.</p>

<h2 id="more-pytorch-ios-demo-apps">More PyTorch iOS Demo Apps</h2>

<h3 id="image-segmentation">Image Segmentation</h3>

<p><a href="https://github.com/pytorch/ios-demo-app/tree/master/ImageSegmentation">Image Segmentation</a> demonstrates a Python script that converts the PyTorch <a href="https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/">DeepLabV3</a> model for mobile apps to use and an iOS app that uses the model to segment images.</p>

<h3 id="object-detection">Object Detection</h3>

<p><a href="https://github.com/pytorch/ios-demo-app/tree/master/ObjectDetection">Object Detection</a> demonstrates how to convert the popular <a href="https://pytorch.org/hub/ultralytics_yolov5/">YOLOv5</a> model and use it on an iOS app that detects objects from pictures in your photos, taken with camera, or with live camera.</p>

<h3 id="neural-machine-translation">Neural Machine Translation</h3>

<p><a href="https://github.com/pytorch/ios-demo-app/tree/master/Seq2SeqNMT">Neural Machine Translation</a> demonstrates how to convert a sequence-to-sequence neural machine translation model trained with the code in the <a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html">PyTorch NMT tutorial</a> and use the model in an iOS app to do French-English translation.</p>

<h3 id="question-answering">Question Answering</h3>

<p><a href="https://github.com/pytorch/ios-demo-app/tree/master/QuestionAnswering">Question Answering</a> demonstrates how to convert a powerful transformer QA model and use the model in an iOS app to answer questions about PyTorch Mobile and more.</p>

<h3 id="vision-transformer">Vision Transformer</h3>

<p><a href="https://github.com/pytorch/ios-demo-app/tree/master/ViT4MNIST">Vision Transformer</a> demonstrates how to use Facebook’s latest Vision Transformer <a href="https://github.com/facebookresearch/deit">DeiT</a> model to do image classification, and how convert another Vision Transformer model and use it in an iOS app to perform handwritten digit recognition.</p>

<h3 id="speech-recognition">Speech recognition</h3>

<p><a href="https://github.com/pytorch/ios-demo-app/tree/master/SpeechRecognition">Speech Recognition</a> demonstrates how to convert Facebook AI’s wav2vec 2.0, one of the leading models in speech recognition, to TorchScript and how to use the scripted model in an iOS app to perform speech recognition.</p>

<h3 id="video-classification">Video Classification</h3>

<p><a href="https://github.com/pytorch/ios-demo-app/tree/master/TorchVideo">TorchVideo</a> demonstrates how to use a pre-trained video classification model, available at the newly released <a href="https://github.com/facebookresearch/pytorchvideo">PyTorchVideo</a>, on iOS to see video classification results, updated per second while the video plays, on tested videos, videos from the Photos library, or even real-time videos.</p>

<h2 id="pytorch-ios-tutorial-and-recipes">PyTorch iOS Tutorial and Recipes</h2>

<h3 id="image-segmentation-deeplabv3-on-ios"><a href="https://pytorch.org/tutorials/beginner/deeplabv3_on_ios.html">Image Segmentation DeepLabV3 on iOS</a></h3>

<p>A comprehensive step-by-step tutorial on how to prepare and run the PyTorch DeepLabV3 image segmentation model on iOS.</p>

<h3 id="pytorch-mobile-performance-recipes"><a href="https://pytorch.org/tutorials/recipes/mobile_perf.html">PyTorch Mobile Performance Recipes</a></h3>

<p>List of recipes for performance optimizations for using PyTorch on Mobile.</p>

<h3 id="fuse-modules-recipe"><a href="https://pytorch.org/tutorials/recipes/fuse.html">Fuse Modules recipe</a></h3>

<p>Learn how to fuse a list of PyTorch modules into a single module to reduce the model size before quantization.</p>

<h3 id="quantization-for-mobile-recipe"><a href="https://pytorch.org/tutorials/recipes/quantization.html">Quantization for Mobile Recipe</a></h3>

<p>Learn how to reduce the model size and make it run faster without losing much on accuracy.</p>

<h3 id="script-and-optimize-for-mobile"><a href="https://pytorch.org/tutorials/recipes/script_optimized.html">Script and Optimize for Mobile</a></h3>

<p>Learn how to convert the model to TorchScipt and (optional) optimize it for mobile apps.</p>

<h3 id="model-preparation-for-ios-recipe"><a href="https://pytorch.org/tutorials/recipes/model_preparation_ios.html">Model Preparation for iOS Recipe</a></h3>

<p>Learn how to add the model in an iOS project and use PyTorch pod for iOS.</p>

<h2 id="build-pytorch-ios-libraries-from-source">Build PyTorch iOS Libraries from Source</h2>

<p>To track the latest updates for iOS, you can build the PyTorch iOS libraries from the source code.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone --recursive https://github.com/pytorch/pytorch
cd pytorch
# if you are updating an existing checkout
git submodule sync
git submodule update --init --recursive
</code></pre></div></div>

<blockquote>
  <p>Make sure you have <code class="language-plaintext highlighter-rouge">cmake</code> and Python installed correctly on your local machine. We recommend following the <a href="https://github.com/pytorch/pytorch">Pytorch Github page</a> to set up the Python development environment</p>
</blockquote>

<h3 id="build-libtorch-for-ios-simulators">Build LibTorch for iOS Simulators</h3>

<p>Open terminal and navigate to the PyTorch root directory. Run the following command (if you already build LibTorch for iOS devices (see below), run <code class="language-plaintext highlighter-rouge">rm -rf build_ios</code> first):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BUILD_PYTORCH_MOBILE=1 IOS_PLATFORM=SIMULATOR ./scripts/build_ios.sh
</code></pre></div></div>
<p>After the build succeeds, all static libraries and header files will be generated under <code class="language-plaintext highlighter-rouge">build_ios/install</code></p>

<h3 id="build-libtorch-for-arm64-devices">Build LibTorch for arm64 Devices</h3>

<p>Open terminal and navigate to the PyTorch root directory. Run the following command (if you already build LibTorch for iOS simulators, run <code class="language-plaintext highlighter-rouge">rm -rf build_ios</code> first):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BUILD_PYTORCH_MOBILE=1 IOS_ARCH=arm64 ./scripts/build_ios.sh
</code></pre></div></div>
<p>After the build succeeds, all static libraries and header files will be generated under <code class="language-plaintext highlighter-rouge">build_ios/install</code></p>

<h3 id="xcode-setup">XCode Setup</h3>

<p>Open your project in XCode, go to your project Target’s <code class="language-plaintext highlighter-rouge">Build Phases</code> - <code class="language-plaintext highlighter-rouge">Link Binaries With Libraries</code>, click the + sign and add all the library files located in <code class="language-plaintext highlighter-rouge">build_ios/install/lib</code>. Navigate to the project <code class="language-plaintext highlighter-rouge">Build Settings</code>, set the value <strong>Header Search Paths</strong> to <code class="language-plaintext highlighter-rouge">build_ios/install/include</code> and <strong>Library Search Paths</strong> to <code class="language-plaintext highlighter-rouge">build_ios/install/lib</code>.</p>

<p>In the build settings, search for <strong>other linker flags</strong>.  Add a custom linker flag below</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-all_load
</code></pre></div></div>

<p>To use the custom built libraries the project, replace <code class="language-plaintext highlighter-rouge">#import &lt;LibTorch/LibTorch.h&gt;</code> (in <code class="language-plaintext highlighter-rouge">TorchModule.mm</code>) which is needed when using LibTorch via Cocoapods with the code below:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#include "ATen/ATen.h"
#include "caffe2/core/timer.h"
#include "caffe2/utils/string_utils.h"
#include "torch/csrc/autograd/grad_mode.h"
#include "torch/csrc/jit/serialization/import.h"
#include "torch/script.h"
</code></pre></div></div>

<p>Finally, disable bitcode for your target by selecting the Build Settings, searching for <strong>Enable Bitcode</strong>, and set the value to <strong>No</strong>.</p>

<h2 id="custom-build">Custom Build</h2>

<p>Starting from 1.4.0, PyTorch supports custom build. You can now build the PyTorch library that only contains the operators needed by your model. To do that, follow the steps below</p>

<p>1. Verify your PyTorch version is 1.4.0 or above. You can do that by checking the value of <code class="language-plaintext highlighter-rouge">torch.__version__</code>.</p>

<p>2. To dump the operators in your model, say <code class="language-plaintext highlighter-rouge">MobileNetV2</code>, run the following lines of Python code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span><span class="p">,</span> <span class="n">yaml</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'MobileNetV2.pt'</span><span class="p">)</span>
<span class="n">ops</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="n">export_opnames</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'MobileNetV2.yaml'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">output</span><span class="p">:</span>
    <span class="n">yaml</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</code></pre></div></div>
<p>In the snippet above, you first need to load the ScriptModule. Then, use <code class="language-plaintext highlighter-rouge">export_opnames</code> to return a list of operator names of the ScriptModule and its submodules. Lastly, save the result in a yaml file.</p>

<p>3. To run the iOS build script locally with the prepared yaml list of operators, pass in the yaml file generate from the last step into the environment variable <code class="language-plaintext highlighter-rouge">SELECTED_OP_LIST</code>. Also in the arguments, specify <code class="language-plaintext highlighter-rouge">BUILD_PYTORCH_MOBILE=1</code> as well as the platform/architechture type. Take the arm64 build for example, the command should be:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SELECTED_OP_LIST=MobileNetV2.yaml BUILD_PYTORCH_MOBILE=1 IOS_ARCH=arm64 ./scripts/build_ios.sh
</code></pre></div></div>
<p>4. After the build succeeds, you can integrate the result libraries to your project by following the <a href="#xcode-setup">XCode Setup</a> section above.</p>

<p>5. The last step is to add a single line of C++ code before running <code class="language-plaintext highlighter-rouge">forward</code>. This is because by default JIT will do some optimizations on operators (fusion for example), which might break the consistency with the ops we dumped from the model.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">GraphOptimizerEnabledGuard</span> <span class="nf">guard</span><span class="p">(</span><span class="nb">false</span><span class="p">);</span>
</code></pre></div></div>

<h2 id="ios-tutorials">iOS Tutorials</h2>

<p>Watch the following <a href="https://youtu.be/amTepUIR93k">video</a> as PyTorch Partner Engineer Brad Heintz walks through steps for setting up the PyTorch Runtime for iOS projects:</p>

<p><a href="https://youtu.be/amTepUIR93k&quot; PyTorch Mobile Runtime for iOS&quot;"><img src="https://i.ytimg.com/vi/JFy3uHyqXn0/maxresdefault.jpg" alt="PyTorch Mobile Runtime for iOS" height="75%" width="75%" /></a></p>

<p>The corresponding code can be found <a href="https://github.com/pytorch/workshops/tree/master/PTMobileWalkthruIOS">here</a>.</p>

<p>Additionally, checkout our <a href="https://pytorch.org/tutorials/recipes/mobile_perf.html">Mobile Performance Recipes</a> which cover how to optimize your model and check if optimizations helped via benchmarking.</p>

<h2 id="api-docs">API Docs</h2>

<p>Currently, the iOS framework uses the Pytorch C++ front-end APIs directly. The C++ document can be found <a href="https://pytorch.org/cppdocs/">here</a>. To learn more about it, we recommend exploring the <a href="https://pytorch.org/tutorials/advanced/cpp_frontend.html">C++ front-end tutorials</a> on PyTorch webpage.</p>

<h2 id="issues-and-contribution">Issues and Contribution</h2>

<p>If you have any questions or want to contribute to PyTorch, please feel free to drop issues or open a pull request to get in touch.</p>

<!-- Do not remove the below script -->

<script page-id="ios" src="/assets/menu-tab-selection.js"></script>


                </article>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>공식 문서 (영어)</h2>
        <p>PyTorch 공식 문서입니다.</p>
        <a class="with-right-arrow" href="https://pytorch.org/docs" target="_blank">공식 문서로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 튜토리얼</h2>
        <p>한국어로 번역 중인 PyTorch 튜토리얼입니다.</p>
        <a class="with-right-arrow" href="https://tutorials.pytorch.kr/">튜토리얼로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>커뮤니티</h2>
        <p>다른 사용자들과 의견을 나눠보세요!</p>
        <a class="with-right-arrow" href="https://discuss.pytorch.kr">커뮤니티로 이동</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="http://localhost:4000" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="https://pytorch.org">PyTorch 홈페이지 (공식)</a></li>
          <li><a href="https://pytorch.org" target="_blank">공식 홈페이지</a></li>
          <li><a href="https://pytorch.org/tutorials" target="_blank">공식 튜토리얼</a></li>
          <li><a href="https://pytorch.org/docs" target="_blank">공식 문서</a></li>
        </ul>
      </div>

      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="">한국 사용자 모임</a></li>
          <li><a href="/about">사이트 소개</a></li>
          <li><a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a></li>
          <li><a href="https://github.com/9bow/PyTorch-tutorials-kr" target="_blank">한국어 튜토리얼 저장소</a></li>
        </ul>
      </div>
    </div>

    <div class="trademark-disclaimer">
      <ul>
        <li>이 사이트는 PyTorch 한국어 사용자 커뮤니티로 Facebook, Inc와 관련이 없습니다. PyTorch, PyTorch 로고 및 모든 관련 표기는 Facebook, Inc의 상표입니다.</li>
        <li>This site is a user community and is not related with Facebook, Inc. PyTorch, the PyTorch logo and any related marks are trademarks of Facebook, Inc.</li>
      </ul>
    </div>
  </div>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-156349638-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-156349638-1');
</script>

</footer>

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="container">
      <div class="mobile-main-menu-header-container">
        <a class="header-logo" href="http://localhost:4000" aria-label="PyTorch"></a>
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">

    <div class="main-menu">
      <ul>

        <li class="main-menu-item ">
          <a href="/get-started">시작하기</a>
        </li>

        <li class="main-menu-item">
          <a href="https://tutorials.pytorch.kr/">튜토리얼</a>
        </li>

        <li class="main-menu-item">
          <a href="/hub">허브</a>
        </li>

        <li class="main-menu-item">
          <a href="https://discuss.pytorch.kr">커뮤니티</a>
        </li>

      </ul>
    </div>

  </div>
</div>


<script src="/assets/mobile-menu.js"></script>
<script src="/assets/scroll-to-anchor.js"></script>
<script src="/assets/external-links-new-tab.js"></script>
<!-- 
  <script src="/assets/search-bar.js"></script>

<script src="/assets/cookie-banner.js"></script> -->

<script type="text/javascript">
  mobileMenu.bind();
  anchors.add('.pytorch-article h2, .pytorch-article h3, .pytorch-article h4, .pytorch-article h5');

  // Add class to links that have code blocks, since we cannot create links in code blocks
  $("a code.highlighter-rouge").each(function(e) {
    $(this).closest("a").addClass("has-code");
  });

  scrollToAnchor.bind();

  var hasStaticHeader = $(".blog-header, .blog-detail-header, .resources-header, .get-started-header, .features-header, .ecosystem-header, .hub-header, .mobile-header").length > 0;

  if (!hasStaticHeader) {
    $(window).on("scroll", function() {
      var top = $(this).scrollTop();
      var fullPosition = $(".main-background").height() - $(".header-holder").height();

      if (top <= 40) {
        $(".header-holder").css({"backgroundColor": "rgba(0, 0, 0, 0.165)"});
      } else if (top >= fullPosition) {
        $(".header-holder").css({"backgroundColor": "#000000"});
      } else {
        var bgColor = "rgba(0, 0, 0, " + top / fullPosition + ")";
        $(".header-holder").css({"backgroundColor": bgColor});
      }
    });
  }
</script>

<script src="/assets/track-events.js"></script>
<script>trackEvents.bind();</script>


  </body>
</html>

<script src="/assets/mobile-page-sidebar.js"></script>
